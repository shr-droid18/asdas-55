{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8f3bda-94cf-40ba-9ba0-72920897ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Rescaling, GlobalAveragePooling2D, Multiply\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1000d4d-3027-46f7-8e67-4fa7a6084431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2531 files belonging to 4 classes.\n",
      "Found 633 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define your data\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'archive/split_leaves/train',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'archive/split_leaves/validation',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c3ba63-c634-4623-9729-483f15f12098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale images\n",
    "rescale = Rescaling(1./255)\n",
    "\n",
    "\n",
    "# Channel Attention Module\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel = input_feature.shape[-1]\n",
    "    \n",
    "    shared_layer_one = Dense(channel // ratio, activation='relu', kernel_initializer='he_normal', use_bias=True)\n",
    "    shared_layer_two = Dense(channel, kernel_initializer='he_normal', use_bias=True)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    \n",
    "    max_pool = layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    \n",
    "    cbam_feature = layers.Add()([avg_pool, max_pool])\n",
    "    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n",
    "    \n",
    "    return Multiply()([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad119a93-182a-4b0e-95a8-ec943da4e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model with hyperparameters\n",
    "def build_model(lr, dropout1, dropout2, dropout3):\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = rescale(inputs)\n",
    "\n",
    "    # First block\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = channel_attention(x)  \n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropout1)(x)\n",
    "\n",
    "    # Second block\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = channel_attention(x)  \n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropout2)(x)\n",
    "\n",
    "    # Third block\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = channel_attention(x)  \n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(dropout3)(x)\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    outputs = Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model with given learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),  \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45afb7e9-2477-4098-983a-e9897c026f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firefly optimization for hyperparameters\n",
    "class FireflyOptimization:\n",
    "    def __init__(self, objective, bounds, n_fireflies=10, max_iter=10, alpha=0.5, beta=0.2, gamma=1.0):\n",
    "        self.objective = objective\n",
    "        self.bounds = bounds\n",
    "        self.n_fireflies = n_fireflies\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.fireflies = np.random.rand(n_fireflies, len(bounds))  # Random initialization\n",
    "        \n",
    "        # Scale fireflies to the bounds\n",
    "        for i in range(len(bounds)):\n",
    "            min_bound, max_bound = bounds[i]\n",
    "            self.fireflies[:, i] = min_bound + self.fireflies[:, i] * (max_bound - min_bound)\n",
    "        \n",
    "        self.fitness = np.array([self.objective(firefly) for firefly in self.fireflies])\n",
    "    \n",
    "    def optimize(self):\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.n_fireflies):\n",
    "                for j in range(self.n_fireflies):\n",
    "                    if self.fitness[j] < self.fitness[i]:\n",
    "                        distance = euclidean(self.fireflies[i], self.fireflies[j])\n",
    "                        beta = self.beta * np.exp(-self.gamma * distance ** 2)\n",
    "                        self.fireflies[i] += beta * (self.fireflies[j] - self.fireflies[i]) \\\n",
    "                                           + self.alpha * (np.random.rand(len(self.bounds)) - 0.5)\n",
    "                        \n",
    "                        # Clip firefly position to stay within bounds\n",
    "                        for k in range(len(self.bounds)):\n",
    "                            min_bound, max_bound = self.bounds[k]\n",
    "                            self.fireflies[i, k] = np.clip(self.fireflies[i, k], min_bound, max_bound)\n",
    "                        \n",
    "                        # Recalculate fitness\n",
    "                        self.fitness[i] = self.objective(self.fireflies[i])\n",
    "            \n",
    "            # Sort fireflies by fitness\n",
    "            idx = np.argsort(self.fitness)\n",
    "            self.fireflies = self.fireflies[idx]\n",
    "            self.fitness = self.fitness[idx]\n",
    "            \n",
    "            print(f\"Iteration {t+1}/{self.max_iter} | Best loss: {self.fitness[0]}\")\n",
    "        \n",
    "        return self.fireflies[0], self.fitness[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40c48fa-6da8-443a-83df-e96a36e0cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for optimization\n",
    "def objective_function(params):\n",
    "    lr, dropout1, dropout2, dropout3 = params\n",
    "    \n",
    "    # Build the model with the hyperparameters\n",
    "    model = build_model(lr, dropout1, dropout2, dropout3)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "    # Train the model for a small number of epochs to evaluate\n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs=5,  # Limit for faster tuning\n",
    "                        validation_data=validation_dataset,\n",
    "                        callbacks=[early_stopping, lr_scheduler],\n",
    "                        verbose=0)\n",
    "    \n",
    "    # Return the final validation loss\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2321b7-2ea5-4248-bd5e-44494d8f7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for hyperparameters: [learning_rate, dropout1, dropout2, dropout3]\n",
    "bounds = [(1e-5, 1e-2), (0.1, 0.6), (0.1, 0.6), (0.1, 0.6)]\n",
    "\n",
    "\n",
    "# Run Firefly Optimization`\n",
    "foa = FireflyOptimization(objective_function, bounds, n_fireflies=10, max_iter=10)\n",
    "best_params, best_loss = foa.optimize()\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation loss: {best_loss}\")\n",
    "\n",
    "# Final model with the best hyperparameters\n",
    "best_lr, best_dropout1, best_dropout2, best_dropout3 = best_params\n",
    "final_model = build_model(best_lr, best_dropout1, best_dropout2, best_dropout3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23441950-81ad-4303-a3ae-6e6f6c92b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model\n",
    "final_history = final_model.fit(train_dataset,\n",
    "                                epochs=20,\n",
    "                                validation_data=validation_dataset,\n",
    "                                callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "final_model.save('final_model_with_firefly.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
